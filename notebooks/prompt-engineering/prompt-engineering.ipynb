{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_random_exponential, retry_if_exception_type\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import HuggingFaceHub,LLMChain\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from io import StringIO\n",
    "import streamlit as st\n",
    "import re\n",
    "import os\n",
    "import openai\n",
    "import ast\n",
    "import json\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel, Field, validator\n",
    "# Decorator for automatic retry requests\n",
    "@retry(\n",
    "    retry = retry_if_exception_type((openai.error.APIError, openai.error.APIConnectionError, openai.error.RateLimitError, openai.error.ServiceUnavailableError, openai.error.Timeout)),\n",
    "    # Function to add random exponential backoff to a request\n",
    "    wait = wait_random_exponential(multiplier = 1, max = 60),\n",
    "    stop = stop_after_attempt(10)\n",
    ")\n",
    "def run_llm_chain(hub_chain,user_input):\n",
    "    output =hub_chain.run(input=user_input)\n",
    "    print(output)     \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, conlist\n",
    "from typing import List, Optional, Tuple\n",
    "class OutputResult(BaseModel):\n",
    "    key: conlist(str, min_length=3, max_length=5) = Field(description=\"The key with the story parameters. Must contain between 3 and 5 parameters\")\n",
    "    story:str = Field(description=\"The generated story for the given key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, conlist\n",
    "from typing import List, Optional, Tuple\n",
    "class InstructionResult(BaseModel):\n",
    "    key: conlist(str, min_length=3, max_length=5) = Field(description=\"The key with the story parameters. Must contain between 3 and 5 parameters\")\n",
    "    instruction:str = Field(description=\"Instruction on how to generate the story given the key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import HuggingFaceHub,LLMChain\n",
    "from dotenv import load_dotenv\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from io import StringIO\n",
    "import streamlit as st\n",
    "import re\n",
    "import os\n",
    "import openai\n",
    "import ast\n",
    "import json\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "def createDataset(iterations, key, story_type, instructions,style) -> pd.DataFrame:\n",
    "    import os\n",
    "    import openai\n",
    "    import ast\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "# initialize the models\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    openai = ChatOpenAI(             \n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        openai_api_key=openai.api_key,\n",
    "        temperature=1.5\n",
    "    )  \n",
    "\n",
    "    \n",
    "    examples = [          \n",
    "            {\n",
    "                \"input\": \"Generate a tuple with first part a key built like this [age,gender, superpower], and the value in the tuple will be an entire story of maximum 100 words with detailed description for a super-hero with the given age, of the given gender and with the given superpower \",\n",
    "                \"output\": OutputResult.model_validate({\n",
    "                    \"key\": [\"18\", \"man\", \"invisibility\"],\n",
    "                    \"story\": \"A 18 year old man, tall with a strong yet athletic build. Noir eyes and light brown hair that seems to be a reflection of the warmth of his personality. His superpower of invisibility make him silent, introspective and observant. He knows when to be seen and when to remain invisible in the background; like a silent guardian protecting those around him. With a strong sense of justice and power, he is an invaluable asset to those he holds near and dear. His kind and compassionate spirit give him an aura of protectiveness, making him a person of strength and courage in difficult moments.\"            \n",
    "                     }).model_dump_json().replace(\"{\", \"{{\").replace(\"}\", \"}}\"),\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"Generate a tuple with first part a key built like this [product ,theme, details], and the value in the tuple will be a gingle of maximum 100 words with commercial for the given product, in the given theme incorporating the provided details.\",\n",
    "                \"output\": OutputResult.model_validate({\n",
    "                    \"key\": [\"Whiskers\", \"happy\", \"cat food-holiday season price reductions-great for your cat\"],\n",
    "                    \"story\": \"We are so happy to announce holiday discounts for the best cat food outhere! For happy and healthy cat choose Whiskers! Meow!\"            \n",
    "                     }).model_dump_json().replace(\"{\", \"{{\").replace(\"}\", \"}}\"),                \n",
    "            },\n",
    "             {\n",
    "                \"input\": \"Generate a tuple with first part a key built like this [fictional character ,location, adventure], and the value in the tuple will be a story of maximum 100 words describing an adventure of the given fictional character in the provided location.\",\n",
    "                \"output\": OutputResult.model_validate({\n",
    "                    \"key\": [\"Baba Yaga\", \"Asia\", \"getting no respect\"],\n",
    "                    \"story\": \"Once upon a time Baba Yaga wondered far far away from her home and ended up in remote Hokkaido island. She was used to locals showing her great respect out of fear and also because she was always one of the pillars of Slavic culture. But in Hokkaido the locals knew nothing about her, and she was very disappointed because they have shown her no respect. Eventually she decided there is no place like home and went back\"            \n",
    "                     }).model_dump_json().replace(\"{\", \"{{\").replace(\"}\", \"}}\"),     \n",
    "            },\n",
    "        ]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # create a example template\n",
    "    example_template = \"\"\"\n",
    "        User: {input}\n",
    "        AI: {output}\n",
    "    \"\"\"\n",
    "    # create a prompt example from above template\n",
    "    example_prompt = PromptTemplate(\n",
    "        input_variables=[\"input\", \"output\"],\n",
    "        template=example_template\n",
    "    )\n",
    "\n",
    "    parser = PydanticOutputParser(pydantic_object=OutputResult)\n",
    "\n",
    "    # now break our previous prompt into a prefix and suffix\n",
    "    # the prefix is our instructions    \n",
    "    prefix = \"\"\"You are a helpful assistant great in story telling. You are very diverse and creative. You need to generate a dataset where the key would be generated values string representing the story parameters according to the user given instructions, and the value will be a story written given this key. Transform the output into structured object given those instructions: {format_instructions} Here are a few examples on how to generate the content of the dataset:\n",
    "    \"\"\"\n",
    "\n",
    "    # and the suffix our user input and output indicator\n",
    "    suffix = \"\"\"\n",
    "    User: {input}\n",
    "    AI:\"\"\"\n",
    "\n",
    "\n",
    "    # now create the few shot prompt template\n",
    "    few_shot_prompt_template = FewShotPromptTemplate(\n",
    "        examples=examples,\n",
    "        example_prompt=example_prompt,\n",
    "        prefix=prefix,\n",
    "        suffix=suffix,\n",
    "        input_variables=[\"input\"],\n",
    "        example_separator=\"\\n\\n\",\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},    \n",
    "    )\n",
    "\n",
    "    f_prompt = \"Generate a tuple with first part a key built like this [{key}], and the value in the tuple will be an entire {type} of maximum 100 words .{instructions}. {style}\"\n",
    "    user_input = f_prompt.format(key=key, type=story_type,instructions = instructions, style=style)\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(iterations):\n",
    "            hub_chain = LLMChain(prompt=few_shot_prompt_template,llm=openai,verbose=True)              \n",
    "            output  = run_llm_chain(hub_chain,user_input)                          \n",
    "            # # Extract the first and second elements as strings\n",
    "            try:\n",
    "                parsed_result = parser.parse(output)\n",
    "                print(parsed_result)\n",
    "                print(f\"\"\"\n",
    "                    key: {\", \".join(parsed_result.key) if parsed_result.key else 'Not specified'}\n",
    "                    story: {parsed_result.story if parsed_result.story else 'Not specified'}\n",
    "                \"\"\")\n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "           \n",
    "            first_string = \", \".join(parsed_result.key) if parsed_result.key else 'Not specified'\n",
    "            print('first string:',first_string)\n",
    "\n",
    "            second_string = parsed_result.story if parsed_result.story else 'Not specified'\n",
    "            print('second string:',second_string)      \n",
    "            \n",
    "            \n",
    "\n",
    "            # Access and print the key-value pairs\n",
    "            \n",
    "            new_row = {\n",
    "            'keywords':key, \n",
    "            'story_type':story_type, \n",
    "            'instructions':instructions,         \n",
    "            'generated_key':first_string,\n",
    "            'generated_value': second_string\n",
    "            }\n",
    "            new_row = pd.DataFrame([new_row])\n",
    "            df = pd.concat([df, new_row], axis=0, ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createInstructions(genre):\n",
    "    import os\n",
    "    import openai\n",
    "    import ast\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "# initialize the models\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    openai = ChatOpenAI(             \n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        openai_api_key=openai.api_key,\n",
    "        temperature=1.5\n",
    "    )  \n",
    "\n",
    "    \n",
    "    examples = [          \n",
    "            {\n",
    "                \"input\": \"Please specify three parameters for sci-fi story, and provide instruction how to generate a story based on those parameters\",\n",
    "                \"output\": InstructionResult.model_validate({\n",
    "                    \"key\": [\"hero name\", \"location the story takes place in\", \"general outline of the hero's adventure\"],\n",
    "                    \"instruction\": \"please generate a sci-fi story, given the hero name, which takes place at the specified location and adheres to the general outline of the hero's adventure .\"            \n",
    "                     }).model_dump_json().replace(\"{\", \"{{\").replace(\"}\", \"}}\"),\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"Please specify three parameters for food recipe, and provide instruction how to generate a recipe based on those parameters.\",\n",
    "                \"output\": InstructionResult.model_validate({\n",
    "                    \"key\": [\"name of raw material\", \"cooking type (fried, baked etc)\", \"kitchen style (Asian, European etc)\"],\n",
    "                    \"instruction\": \"please generate a recipe, given the raw material and the type of cooking, the recipe should belong to the specified kitchen style.\"            \n",
    "                     }).model_dump_json().replace(\"{\", \"{{\").replace(\"}\", \"}}\"),                \n",
    "            },\n",
    "             {\n",
    "                \"input\": \"Please specify three parameters for a strength workout, and provide instruction how to generate a workout based on those parameters.\",\n",
    "                \"output\": InstructionResult.model_validate({\n",
    "                    \"key\": [\"name of the muscle group (upper, lower, core)\", \"name of type of exercise (super sets, tri sets, isometric, eccentric)\",\"weight\"],\n",
    "                    \"instruction\": \"Given the specified muscle group build a workout for this muscle group of the specified exercise type and with the given weights.\"            \n",
    "                     }).model_dump_json().replace(\"{\", \"{{\").replace(\"}\", \"}}\"),     \n",
    "            },\n",
    "        ]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # create a example template\n",
    "    example_template = \"\"\"\n",
    "        User: {input}\n",
    "        AI: {output}\n",
    "    \"\"\"\n",
    "    # create a prompt example from above template\n",
    "    example_prompt = PromptTemplate(\n",
    "        input_variables=[\"input\", \"output\"],\n",
    "        template=example_template\n",
    "    )\n",
    "\n",
    "    parser = PydanticOutputParser(pydantic_object=InstructionResult)\n",
    "\n",
    "    # now break our previous prompt into a prefix and suffix\n",
    "    # the prefix is our instructions    \n",
    "    prefix = \"\"\"You are a helpful story generation assistant. Given a story domain, please generate three parameters which could be used to generate distinct stories for this domain, along with instruction on how to use the parameters to generate the story. Transform the output into structured object given those instructions: {format_instructions} Here are a few examples on how to generate the content of the dataset:\n",
    "    \"\"\"\n",
    "\n",
    "    # and the suffix our user input and output indicator\n",
    "    suffix = \"\"\"\n",
    "    User: {input}\n",
    "    AI:\"\"\"\n",
    "\n",
    "\n",
    "    # now create the few shot prompt template\n",
    "    few_shot_prompt_template = FewShotPromptTemplate(\n",
    "        examples=examples,\n",
    "        example_prompt=example_prompt,\n",
    "        prefix=prefix,\n",
    "        suffix=suffix,\n",
    "        input_variables=[\"input\"],\n",
    "        example_separator=\"\\n\\n\",\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},    \n",
    "    )\n",
    "\n",
    "    f_prompt = \"Please specify three parameters for a {genre} , and provide instruction how to generate a {genre} based on those parameters \"\n",
    "    user_input = f_prompt.format(genre=genre)    \n",
    "    \n",
    "    hub_chain = LLMChain(prompt=few_shot_prompt_template,llm=openai,verbose=True)              \n",
    "    output  = run_llm_chain(hub_chain,user_input)                          \n",
    "    # Extract the first and second elements as strings\n",
    "    try:\n",
    "        parsed_result = parser.parse(output)\n",
    "        print(parsed_result)\n",
    "        print(f\"\"\"\n",
    "            key: {\", \".join(parsed_result.key) if parsed_result.key else 'Not specified'}\n",
    "            instruction: {parsed_result.instruction if parsed_result.instruction else 'Not specified'}\n",
    "        \"\"\")\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        \n",
    "           \n",
    "    key = \", \".join(parsed_result.key) if parsed_result.key else 'Not specified'\n",
    "    print('key:',key)\n",
    "\n",
    "    instruction = parsed_result.instruction if parsed_result.instruction else 'Not specified'\n",
    "    print('instruction:',instruction)      \n",
    "            \n",
    "    return key,instruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key,instruction = createInstructions('fairytale story')\n",
    "print('key: ',key,' ,instructions: ',instruction)\n",
    "\n",
    "key,instruction = createInstructions('commercial jingle')\n",
    "print('key: ',key,' ,instructions: ',instruction)\n",
    "\n",
    "key,instruction = createInstructions('news item')\n",
    "print('key: ',key,' ,instructions: ',instruction)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = createDataset(10, 'news agency, location, news item', 'news item','The news item will be a report of the given news agency regarding the provided location and revolving around the news item which takes place in that location','Be very precise and stick to the facts with the key parameters values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateDataset(genre,size, style) ->pd.DataFrame:\n",
    "    key,instruction = createInstructions(genre)\n",
    "    df = createDataset(size,key,genre,instruction,style)\n",
    "    return df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsItems_df = generateDataset('news item',10,'Be very precise and stick to the facts with the key parameters values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsItems_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_df = createDataset(10, 'muscle group, training type, training weight', 'a workout plan','The workout plan will be for the specified muscle group with the given training type (such as supersets, isometric workout, unilateral workout, eccentric workout etc.) and the given weight','Be very precise and stick to the facts with the key parameters values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_df = createDataset(10, 'fictional protagonist, fictional realm, adventure outline', 'a sci-fi story','a sci-fi story about the fictional protagonist , taking place in the described realm and based on the given adventure outline','Be very creative and diverse with the key parameters values, they should not be straightforward but imaginative and diverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gingle_df = createDataset(10, 'product name, catchy slogan, style (lyrical, satirical, funny)' , 'commercial jingle','commercial jingle using the specified product name and a catchy slogan. The style of the jingle should align with the given preference to create a catchy jingle to promote the product.','Be very creative and diverse with the key parameters values, they should not be straightforward but imaginative and diverse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gingle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gingle_df.to_csv(\"../datasets/jingle_generated_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_df = createDataset(5000, 'magical character, location, adventure', 'fairytale story','detailed description of the specified adventure of our magical character taking place in the given location')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "another_df.to_csv(\"../datasets/workout_generated_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invocation of the model only with prompt engineering, no fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is for v1 of the openai package: pypi.org/project/openai\n",
    "#from openai import OpenAI\n",
    "\n",
    "#client = OpenAI()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "f_prompt = \"Given the following parameters: news agency: {news_agency}, location: {location} and news item: {news_item}, generate an elaborate report of that news agency revolving around the provided news item in the provided location. The report should be maximum 100 words \"\n",
    "f_sub_prompt = \"{news_agency},  {location}, {news_item}\"\n",
    "\n",
    "df = pd.read_csv(\"generated_dataset.csv\")\n",
    "prepared_data = df.loc[:,['generated_key','generated_value']]\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "for index, row in prepared_data.head(10).iterrows():\n",
    "  key = row['generated_key']  \n",
    "  # read the next line from the csv\n",
    "  array_of_strings = key.split(\", \")\n",
    "  news_agency = array_of_strings[0]\n",
    "  location = array_of_strings[1]\n",
    "  news_item = array_of_strings[2]\n",
    "\n",
    "  prompt = f_prompt.format(news_agency=news_agency, location=location, news_item=news_item)\n",
    "  sub_prompt = f_sub_prompt.format(news_agency=news_agency, location=location, news_item=news_item)\n",
    "  print(sub_prompt)\n",
    "  print(prompt)\n",
    "  #response = client.completions.create(\n",
    "  response = openai.Completion.create(\n",
    "    model=\"text-davinci-003\",\n",
    "    prompt=prompt,\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=[\"END\"]\n",
    "  )\n",
    "    \n",
    "  finish_reason = response['choices'][0]['finish_reason']\n",
    "  response_txt = response['choices'][0]['text']\n",
    "    \n",
    "  new_row = {\n",
    "      'news_agency':news_agency, \n",
    "      'location':location, \n",
    "      'news_item':news_item, \n",
    "      'prompt':prompt, \n",
    "      'sub_prompt':sub_prompt, \n",
    "      'response_txt':response_txt, \n",
    "      'finish_reason':finish_reason}\n",
    "  new_row = pd.DataFrame([new_row])\n",
    "  new_df = pd.concat([new_df, new_row], axis=0, ignore_index=True)\n",
    "\n",
    "new_df.to_csv(\"de_vinci_prompt_eng.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine tuning the model with the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0baf9a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import openai\n",
    "import subprocess\n",
    "\n",
    "df = pd.read_csv(\"generated_dataset.csv\")\n",
    "\n",
    "prepared_data = df.loc[:,['generated_key','generated_value']]\n",
    "prepared_data.rename(columns={'generated_key':'prompt', 'generated_value':'completion'}, inplace=True)\n",
    "prepared_data.to_csv('prepared_data.csv',index=False)\n",
    "\n",
    "\n",
    "## prepared_data.csv --> prepared_data_prepared.json\n",
    "subprocess.run('openai tools fine_tunes.prepare_data --file prepared_data.csv --quiet'.split())\n",
    "\n",
    "## Start fine-tuning\n",
    "subprocess.run('openai api fine_tunes.create --training_file prepared_data_prepared.jsonl --model davinci --suffix \"StoryGenerationThemed\"'.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Invocation of the fine-tuned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is for v1 of the openai package: pypi.org/project/openai\n",
    "#from openai import OpenAI\n",
    "\n",
    "#client = OpenAI()\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "f_prompt = \"{news_agency}, {location}, {news_item}\"\n",
    "news_agency_input = \"BBC\"\n",
    "location_input = \"Melburn\"\n",
    "news_item_input = \"shark attack\"\n",
    "new_df = pd.DataFrame()\n",
    "prompt = f_prompt.format(news_agency=news_agency_input, location=location_input, news_item=news_item_input)\n",
    "print(prompt)\n",
    "\n",
    "response = openai.Completion.create(\n",
    "    model=\"davinci:ft-personal:storygenerationthemed-2023-12-04-14-10-42\",\n",
    "    prompt=prompt,\n",
    "    temperature=1,\n",
    "    max_tokens=256,\n",
    "    top_p=1,\n",
    "    frequency_penalty=0,\n",
    "    presence_penalty=0,\n",
    "    stop=[\"END\"]\n",
    ")\n",
    "    \n",
    "finish_reason = response['choices'][0]['finish_reason']\n",
    "response_txt = response['choices'][0]['text']\n",
    "print(response_txt)    \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
