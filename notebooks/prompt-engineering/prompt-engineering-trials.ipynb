{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tenacity import retry, stop_after_attempt, wait_random_exponential, retry_if_exception_type\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import HuggingFaceHub,LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from io import StringIO\n",
    "import streamlit as st\n",
    "import re\n",
    "import os\n",
    "import openai\n",
    "import ast\n",
    "import json\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.pydantic_v1 import BaseModel, Field, validator\n",
    "# Decorator for automatic retry requests\n",
    "@retry( #the function retrys to activate the run_llm_chain(RLC) function a few times if the RLC function doesnt work \n",
    "    retry = retry_if_exception_type((openai.OpenAIError, openai.APIConnectionError, openai.Timeout)),\n",
    "    # Function to add random exponential backoff to a request\n",
    "    wait = wait_random_exponential(multiplier = 1, max = 60),\n",
    "    stop = stop_after_attempt(10)\n",
    ")\n",
    "def run_llm_chain(hub_chain,user_input): # the function talks with the LLM\n",
    "    output =hub_chain.run(input=user_input)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, conlist\n",
    "from typing import List, Optional, Tuple\n",
    "class OutputResult(BaseModel):\n",
    "    key: conlist(str, min_length=3, max_length=5) = Field(description=\"The key with the story parameters. Must contain between 3 and 5 parameters\")\n",
    "    story:str = Field(description=\"The generated story for the given key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "60c3c79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import HuggingFaceHub,LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from io import StringIO\n",
    "import streamlit as st\n",
    "import re\n",
    "import os\n",
    "import openai\n",
    "import ast\n",
    "import json\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "def createDatasetSimple(key, story_type, instructions) -> pd.DataFrame:\n",
    "    import os\n",
    "    import openai\n",
    "    import ast\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "# initialize the models\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    openai = ChatOpenAI(             \n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        openai_api_key=openai.api_key,\n",
    "        temperature=1.5\n",
    "    )  \n",
    "\n",
    "    \n",
    "    f_prompt = \"Generate a pair with a key built like this [{key}], and the value in the pair will be an entire {type}.{instructions}.\"\n",
    "    user_input = f_prompt.format(key=key, type=story_type,instructions = instructions)\n",
    "    prompt_template = PromptTemplate(\n",
    "        template=\"{input}\",\n",
    "        input_variables=[\"input\"]        \n",
    "    )\n",
    "   \n",
    "    hub_chain = LLMChain(prompt=prompt_template,llm=openai,verbose=True)              \n",
    "    output  = run_llm_chain(hub_chain,user_input)                          \n",
    "    return output\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "67d55091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGenerate a pair with a key built like this [news agency, location, news item], and the value in the pair will be an entire news item.The news item will be a report of the given news agency regarding the provided location and revolving around the news item which takes place in that location.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Pair 1:\\n\\nKey: [Reuters, New York, Earthquake]\\nValue: \\n\"EARTHQUAKE HITS NEW YORK CITY\\n\\nAccording to witnesses and local officials, a powerful earthquake rocked New York City earlier today. The earthquake, estimated to have a magnitude of 6.5, caused widespread panic as buildings shook and debris fell in various parts of the city. Emergency services are currently assessing the damage and attending to any injured individuals. Residents are urged to stay clear of damaged structures and follow any advisory issued by authorities. More updates on this developing situation will be provided as they become available.\"\\n\\nPair 2:\\n\\nKey: [Associated Press, Paris, Protest]\\nValue:\\n\"PROTESTERS TAKE TO THE STREETS IN PARIS\\n\\nReports from Paris indicate that thousands of protesters have taken to the streets to voice their grievances against recent political developments. The demonstrators, comprising various groups and organizations, are expressing dissent over policies implemented by the government that they claim are discriminatory and harmful to citizens. Authorities are monitoring the situation closely to ensure the safety of both protesters and bystanders. Stay tuned for further updates on this evolving protest in the heart of the French capital.\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = createDatasetSimple('news agency, location, news item', 'news item','The news item will be a report of the given news agency regarding the provided location and revolving around the news item which takes place in that location')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "32e91b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import HuggingFaceHub,LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from io import StringIO\n",
    "import streamlit as st\n",
    "import re\n",
    "import os\n",
    "import openai\n",
    "import ast\n",
    "import json\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "def createDatasetSimpleLength(key, story_type, instructions) -> pd.DataFrame:\n",
    "    import os\n",
    "    import openai\n",
    "    import ast\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "# initialize the models\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    openai = ChatOpenAI(             \n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        openai_api_key=openai.api_key,\n",
    "        temperature=1.5\n",
    "    )  \n",
    "\n",
    "    f_prompt = \"Generate a pair with a key built like this [{key}], and the value in the pair will be an entire {type} of maximum 100 words.{instructions}.\"\n",
    "    user_input = f_prompt.format(key=key, type=story_type,instructions = instructions)\n",
    "    prompt_template = PromptTemplate(\n",
    "        template=\"{input}\",\n",
    "        input_variables=[\"input\"]        \n",
    "    )\n",
    "\n",
    "    \n",
    "    hub_chain = LLMChain(prompt=prompt_template,llm=openai,verbose=True)              \n",
    "    output  = run_llm_chain(hub_chain,user_input)                          \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3552c93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mGenerate a pair with a key built like this [news agency, location, news item], and the value in the pair will be an entire news item of maximum 100 words.The news item will be a report of the given news agency regarding the provided location and revolving around the news item which takes place in that location.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Key: [Reuters, London, COVID-19]\\nValue: \\nBritish Prime Minister Boris Johnson announced new measures today to combat the spread of the COVID-19 virus in London. The city has seen a significant surge in cases in recent weeks, prompting government officials to impose stricter restrictions on social gatherings and non-essential businesses. Johnson urged Londoners to adhere to the new guidelines in order to protect themselves and others from the potentially deadly virus. Health authorities are closely monitoring the situation and are prepared to take further action if necessary to prevent a worsening outbreak in the capital city.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = createDatasetSimpleLength('news agency, location, news item', 'news item','The news item will be a report of the given news agency regarding the provided location and revolving around the news item which takes place in that location')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cdf5a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import HuggingFaceHub,LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from io import StringIO\n",
    "import streamlit as st\n",
    "import re\n",
    "import os\n",
    "import openai\n",
    "import ast\n",
    "import json\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "def createDatasetSimpleRole(key, story_type, instructions) -> pd.DataFrame:\n",
    "    import os\n",
    "    import openai\n",
    "    import ast\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "# initialize the models\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    openai = ChatOpenAI(             \n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        openai_api_key=openai.api_key,\n",
    "        temperature=1.5\n",
    "    )  \n",
    "\n",
    "    prefix = \"\"\"You are a helpful assistant great in story telling. You follow the given instructions in a precise manner.\n",
    "    \"\"\"\n",
    "    f_prompt = \"\"\"{prefix}. Generate a pair with first part a key built like this [{key}], and the value in the pair will be an entire {type}.{instructions}.\n",
    "      Return result maximum 100 words\"\"\"\n",
    "    user_input = f_prompt.format(prefix=prefix,key=key, type=story_type,instructions = instructions)\n",
    "    prompt_template= PromptTemplate(\n",
    "        prefix=prefix, \n",
    "        input_variables=[\"input\"],\n",
    "        template=\"{input}\"\n",
    "    )\n",
    "    hub_chain = LLMChain(prompt=prompt_template,llm=openai,verbose=True)              \n",
    "    output  = run_llm_chain(hub_chain,user_input)                          \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f679b189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful assistant great in story telling. You follow the given instructions in a precise manner.\n",
      "    . Generate a pair with first part a key built like this [news agency, location, news item], and the value in the pair will be an entire news item.The news item will be a report of the given news agency regarding the provided location and revolving around the news item which takes place in that location.\n",
      "      Return result maximum 100 words\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Pair: [ABC News, New York City, weather]\\n\\nValue: ABC News reported from New York City that a winter storm warning has been issued for the entire area. Residents are warned to prepare for heavy snowfall and potential travel disruptions. The city has activated emergency response plans to handle the weather conditions, with snow plows and salt trucks on standby. Schools and some non-essential businesses are expected to close early. It is advised for commuters to stay indoors and travel only if necessary. Tune in to ABC News for live updates on the evolving situation in New York City.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = createDatasetSimpleRole('news agency, location, news item', 'news item','The news item will be a report of the given news agency regarding the provided location and revolving around the news item which takes place in that location')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34ba447b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import HuggingFaceHub,LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from io import StringIO\n",
    "import streamlit as st\n",
    "import re\n",
    "import os\n",
    "import openai\n",
    "import ast\n",
    "import json\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "def createDatasetSimpleFormat(key, story_type, instructions) -> pd.DataFrame:\n",
    "    import os\n",
    "    import openai\n",
    "    import ast\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    \n",
    "    # Initialize the models\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    openai_model = ChatOpenAI(\n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        openai_api_key=openai.api_key,\n",
    "        temperature=1.5\n",
    "    )\n",
    "\n",
    "    prefix = \"\"\"You are a helpful assistant great in storytelling. You follow the given instructions in a precise manner. \n",
    "    Ensure the result is formatted correctly.\"\"\"\n",
    "    parser = PydanticOutputParser(pydantic_object=OutputResult)\n",
    "    # Detailed format instructions\n",
    "    format_instructions = parser.get_format_instructions()\n",
    "\n",
    "    # Construct the full prompt\n",
    "    f_prompt = \"\"\"{prefix}. {format_instructions}. Generate a pair with the first part a key built like this [{key}], \n",
    "    and the value in the pair will be an entire {type}. {instructions}. Ensure the result is a maximum of 100 words.\"\"\"\n",
    "    user_input = f_prompt.format(prefix=prefix, key=key, type=story_type, instructions=instructions, format_instructions=format_instructions)\n",
    "    \n",
    "    prompt_template = PromptTemplate(\n",
    "        prefix=prefix,\n",
    "        template=\"{input}\",\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": format_instructions},\n",
    "    )\n",
    "\n",
    "    # Initialize the LLMChain with the prompt template and OpenAI model\n",
    "    hub_chain = LLMChain(prompt=prompt_template, llm=openai_model, verbose=True)\n",
    "\n",
    "    # Get the output from the LLMChain\n",
    "    output_text = run_llm_chain(hub_chain, user_input)\n",
    "    print(output_text)\n",
    "\n",
    "    # Parse the output text to create an OutputResult object\n",
    "    try:\n",
    "        parsed_result = parser.parse(output_text)                \n",
    "    except (SyntaxError, KeyError, ValueError):\n",
    "        raise ValueError(\"The LLM response could not be parsed into the expected OutputResult format.\")\n",
    "\n",
    "    return parsed_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d073adab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful assistant great in storytelling. You follow the given instructions in a precise manner. \n",
      "    Ensure the result is formatted correctly.. The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"key\": {\"description\": \"The key with the story parameters. Must contain between 3 and 5 parameters\", \"items\": {\"type\": \"string\"}, \"maxItems\": 5, \"minItems\": 3, \"title\": \"Key\", \"type\": \"array\"}, \"story\": {\"description\": \"The generated story for the given key\", \"title\": \"Story\", \"type\": \"string\"}}, \"required\": [\"key\", \"story\"]}\n",
      "```. Generate a pair with the first part a key built like this [news agency, location, news item], \n",
      "    and the value in the pair will be an entire news item. The news item will be a report of the given news agency regarding the provided location and revolving around the news item which takes place in that location. Ensure the result is a maximum of 100 words.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\n",
      "    \"key\": [\"BBC News\", \"London\", \"Brexit Update\"],\n",
      "    \"story\": \"Breaking news from BBC News in London, as Brexit negotiations unfold. Amidst escalating tensions, both sides struggle to reach a consensus on key trade agreements. Citizens express concern over the uncertainty looming over the future of their country's economy. Stay tuned for further updates on this critical issue.\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OutputResult(key=['BBC News', 'London', 'Brexit Update'], story=\"Breaking news from BBC News in London, as Brexit negotiations unfold. Amidst escalating tensions, both sides struggle to reach a consensus on key trade agreements. Citizens express concern over the uncertainty looming over the future of their country's economy. Stay tuned for further updates on this critical issue.\")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = createDatasetSimpleFormat('news agency, location, news item', 'news item','The news item will be a report of the given news agency regarding the provided location and revolving around the news item which takes place in that location')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9bd97922",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import HuggingFaceHub,LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from io import StringIO\n",
    "import streamlit as st\n",
    "import re\n",
    "import os\n",
    "import openai\n",
    "import ast\n",
    "import json\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "def createDatasetSimpleStyle(key, story_type, instructions, style) -> pd.DataFrame:\n",
    "    import os\n",
    "    import openai\n",
    "    import ast\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "    \n",
    "    # Initialize the models\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    openai_model = ChatOpenAI(\n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        openai_api_key=openai.api_key,\n",
    "        temperature=1.5\n",
    "    )\n",
    "\n",
    "    prefix_string = \"\"\"You are a helpful assistant great in storytelling. You follow the given instructions in a precise manner.{style}. \n",
    "    Ensure the result is formatted correctly.\"\"\"\n",
    "    prefix = prefix_string.format(style = style)\n",
    "    parser = PydanticOutputParser(pydantic_object=OutputResult)\n",
    "    # Detailed format instructions\n",
    "    format_instructions = parser.get_format_instructions()\n",
    "\n",
    "    # Construct the full prompt\n",
    "    f_prompt = \"\"\"{prefix}. {format_instructions}.Generate a pair with the first part a key built like this [{key}], \n",
    "    and the value in the pair will be an entire {type}. {instructions}. Ensure the result is a maximum of 100 words.\"\"\"\n",
    "    user_input = f_prompt.format(prefix=prefix, key=key, type=story_type, instructions=instructions, format_instructions=format_instructions)\n",
    "\n",
    "    # Create the prompt template\n",
    "    prompt_template = PromptTemplate(\n",
    "        prefix=prefix,\n",
    "        template=\"{input}\",\n",
    "        input_variables=[\"input\"],\n",
    "        partial_variables={\"format_instructions\": format_instructions},\n",
    "    )\n",
    "\n",
    "    # Initialize the LLMChain with the prompt template and OpenAI model\n",
    "    hub_chain = LLMChain(prompt=prompt_template, llm=openai_model, verbose=True)\n",
    "\n",
    "    # Get the output from the LLMChain\n",
    "    output_text = run_llm_chain(hub_chain, user_input)\n",
    "    print(output_text)\n",
    "\n",
    "    # Parse the output text to create an OutputResult object\n",
    "    try:\n",
    "        parsed_result = parser.parse(output_text)        \n",
    "    except (SyntaxError, KeyError, ValueError):\n",
    "        raise ValueError(\"The LLM response could not be parsed into the expected OutputResult format.\")\n",
    "\n",
    "    return parsed_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da094842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful assistant great in storytelling. You follow the given instructions in a precise manner.You are very diverse and creative. Dont be dull, go wild, invent interesting locations and adventures and fun characters!. \n",
      "    Ensure the result is formatted correctly.. The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"key\": {\"description\": \"The key with the story parameters. Must contain between 3 and 5 parameters\", \"items\": {\"type\": \"string\"}, \"maxItems\": 5, \"minItems\": 3, \"title\": \"Key\", \"type\": \"array\"}, \"story\": {\"description\": \"The generated story for the given key\", \"title\": \"Story\", \"type\": \"string\"}}, \"required\": [\"key\", \"story\"]}\n",
      "```.Generate a pair with the first part a key built like this [news agency, location, news item], \n",
      "    and the value in the pair will be an entire news item. The news item will be a report of the given news agency regarding the provided location and revolving around the news item which takes place in that location. Ensure the result is a maximum of 100 words.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "{\n",
      "    \"key\": [\n",
      "        \"Daily Globe News\", \n",
      "        \"Tropical Island\", \n",
      "        \"Mysterious Disappearance\"\n",
      "    ],\n",
      "    \"story\": \"Breaking news from Daily Globe News! Mystery surrounds the idyllic Tropical Island as reports come in regarding a mysterious disappearance.Click here for updates!\"\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "OutputResult(key=['Daily Globe News', 'Tropical Island', 'Mysterious Disappearance'], story='Breaking news from Daily Globe News! Mystery surrounds the idyllic Tropical Island as reports come in regarding a mysterious disappearance.Click here for updates!')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = createDatasetSimpleStyle('news agency, location, news item', 'news item','The news item will be a report of the given news agency regarding the provided location and revolving around the news item which takes place in that location','You are very diverse and creative. Dont be dull, go wild, invent interesting locations and adventures and fun characters!')\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain import HuggingFaceHub,LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain import FewShotPromptTemplate\n",
    "from langchain.output_parsers import CommaSeparatedListOutputParser\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from io import StringIO\n",
    "import streamlit as st\n",
    "import re\n",
    "import os\n",
    "import openai\n",
    "import ast\n",
    "import json\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import PromptTemplate\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "def createDataset(iterations, key, story_type, instructions,style) -> pd.DataFrame:\n",
    "    import os\n",
    "    import openai\n",
    "    import ast\n",
    "    from langchain.chat_models import ChatOpenAI\n",
    "# initialize the models\n",
    "    openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "    openai = ChatOpenAI(             \n",
    "        model_name=\"gpt-3.5-turbo\",\n",
    "        openai_api_key=openai.api_key,\n",
    "        temperature=1.5\n",
    "    )  \n",
    "\n",
    "    \n",
    "    examples = [          \n",
    "            {\n",
    "                \"input\": \"\"\"Generate a tuple with first part a key built like this [age,gender, superpower], \n",
    "                and the value in the tuple will be an entire story of maximum 100 words with detailed description for a super-hero with the given age, of the given gender and with the given superpower \"\"\",\n",
    "                \"output\": OutputResult.model_validate({\n",
    "                    \"key\": [\"18\", \"man\", \"invisibility\"],\n",
    "                    \"story\": \"\"\"A 18 year old man, tall with a strong yet athletic build. Noir eyes and light brown hair that seems to be a reflection of the warmth of his personality. \n",
    "                    His superpower of invisibility make him silent, \n",
    "                    introspective and observant. He knows when to be seen and when to remain invisible in the background; like a silent guardian protecting those around him. With a strong sense of justice and power,\n",
    "                    he is an invaluable asset to those he holds near and dear. His kind and compassionate spirit give him an aura of protectiveness, making him a person of strength and courage in difficult moments.\"\"\"            \n",
    "                     }).model_dump_json().replace(\"{\", \"{{\").replace(\"}\", \"}}\"),\n",
    "            },\n",
    "            {\n",
    "                \"input\": \"\"\"Generate a tuple with first part a key built like this [product ,theme, details], \n",
    "                and the value in the tuple will be a gingle of maximum 100 words with commercial for the given product, in the given theme incorporating the provided details.\"\"\",\n",
    "                \"output\": OutputResult.model_validate({\n",
    "                    \"key\": [\"Whiskers\", \"happy\", \"cat food-holiday season price reductions-great for your cat\"],\n",
    "                    \"story\": \"We are so happy to announce holiday discounts for the best cat food outhere! For happy and healthy cat choose Whiskers! Meow!\"            \n",
    "                     }).model_dump_json().replace(\"{\", \"{{\").replace(\"}\", \"}}\"),                \n",
    "            },\n",
    "             {\n",
    "                \"input\": \"\"\"Generate a tuple with first part a key built like this [fictional character ,location, adventure], \n",
    "                and the value in the tuple will be a story of maximum 100 words describing an adventure of the given fictional character in the provided location.\"\"\",\n",
    "                \"output\": OutputResult.model_validate({\n",
    "                    \"key\": [\"Baba Yaga\", \"Asia\", \"getting no respect\"],\n",
    "                    \"story\": \"\"\"Once upon a time Baba Yaga wondered far far away from her home and ended up in remote Hokkaido island. \n",
    "                    She was used to locals showing her great respect out of fear and also because she was always one of the pillars of Slavic culture. \n",
    "                    But in Hokkaido the locals knew nothing about her, and she was very disappointed because they have shown her no respect. Eventually she decided there is no place like home and went back\"\"\"            \n",
    "                     }).model_dump_json().replace(\"{\", \"{{\").replace(\"}\", \"}}\"),     \n",
    "            },\n",
    "        ]\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "    # create a example template\n",
    "    example_template = \"\"\"\n",
    "        User: {input}\n",
    "        AI: {output}\n",
    "    \"\"\"\n",
    "    # create a prompt example from above template\n",
    "    example_prompt = PromptTemplate(\n",
    "        input_variables=[\"input\", \"output\"],\n",
    "        template=example_template\n",
    "    )\n",
    "\n",
    "    parser = PydanticOutputParser(pydantic_object=OutputResult)\n",
    "\n",
    "    # now break our previous prompt into a prefix and suffix\n",
    "    # the prefix is our instructions    \n",
    "    prefix = \"\"\"You are a helpful assistant great in story telling. You follow the given instructions in a precise manner. \n",
    "    You need to generate a dataset where the key would be generated values string representing the story parameters according to the user given instructions, and the value will be a story written given this key. \n",
    "    Transform the output into structured object given those instructions: {format_instructions} Here are a few examples on how to generate the content of the dataset:\n",
    "    \"\"\"\n",
    "\n",
    "    # and the suffix our user input and output indicator\n",
    "    suffix = \"\"\"\n",
    "    User: {input}\n",
    "    AI:\"\"\"\n",
    "\n",
    "\n",
    "    # now create the few shot prompt template\n",
    "    few_shot_prompt_template = FewShotPromptTemplate(\n",
    "        examples=examples,\n",
    "        example_prompt=example_prompt,\n",
    "        prefix=prefix,\n",
    "        suffix=suffix,\n",
    "        input_variables=[\"input\"],\n",
    "        example_separator=\"\\n\\n\",\n",
    "        partial_variables={\"format_instructions\": parser.get_format_instructions()},    \n",
    "    )\n",
    "\n",
    "    f_prompt = \"Generate a tuple with first part a key built like this [{key}], and the value in the tuple will be an entire {type} of maximum 100 words .{instructions}. {style}\"\n",
    "    user_input = f_prompt.format(key=key, type=story_type,instructions = instructions, style=style)\n",
    "    df = pd.DataFrame()\n",
    "    for i in range(iterations):\n",
    "            hub_chain = LLMChain(prompt=few_shot_prompt_template,llm=openai,verbose=True)              \n",
    "            output  = run_llm_chain(hub_chain,user_input)                          \n",
    "            # # Extract the first and second elements as strings\n",
    "            try:\n",
    "                parsed_result = parser.parse(output)               \n",
    "            except Exception as e:\n",
    "                print(e)\n",
    "                continue\n",
    "           \n",
    "            first_string = \", \".join(parsed_result.key) if parsed_result.key else 'Not specified'\n",
    "            print('first string:',first_string)\n",
    "\n",
    "            second_string = parsed_result.story if parsed_result.story else 'Not specified'\n",
    "            print('second string:',second_string)      \n",
    "            \n",
    "            \n",
    "\n",
    "            # Access and print the key-value pairs\n",
    "            \n",
    "            new_row = {\n",
    "            'keywords':key, \n",
    "            'story_type':story_type, \n",
    "            'instructions':instructions,         \n",
    "            'generated_key':first_string,\n",
    "            'generated_value': second_string\n",
    "            }\n",
    "            new_row = pd.DataFrame([new_row])\n",
    "            df = pd.concat([df, new_row], axis=0, ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mYou are a helpful assistant great in story telling. You follow the given instructions in a precise manner. \n",
      "    You need to generate a dataset where the key would be generated values string representing the story parameters according to the user given instructions, and the value will be a story written given this key. \n",
      "    Transform the output into structured object given those instructions: The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
      "\n",
      "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
      "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
      "\n",
      "Here is the output schema:\n",
      "```\n",
      "{\"properties\": {\"key\": {\"description\": \"The key with the story parameters. Must contain between 3 and 5 parameters\", \"items\": {\"type\": \"string\"}, \"maxItems\": 5, \"minItems\": 3, \"title\": \"Key\", \"type\": \"array\"}, \"story\": {\"description\": \"The generated story for the given key\", \"title\": \"Story\", \"type\": \"string\"}}, \"required\": [\"key\", \"story\"]}\n",
      "``` Here are a few examples on how to generate the content of the dataset:\n",
      "    \n",
      "\n",
      "\n",
      "        User: Generate a tuple with first part a key built like this [age,gender, superpower], \n",
      "                and the value in the tuple will be an entire story of maximum 100 words with detailed description for a super-hero with the given age, of the given gender and with the given superpower \n",
      "        AI: {\"key\":[\"18\",\"man\",\"invisibility\"],\"story\":\"A 18 year old man, tall with a strong yet athletic build. Noir eyes and light brown hair that seems to be a reflection of the warmth of his personality. \\n                    His superpower of invisibility make him silent, \\n                    introspective and observant. He knows when to be seen and when to remain invisible in the background; like a silent guardian protecting those around him. With a strong sense of justice and power,\\n                    he is an invaluable asset to those he holds near and dear. His kind and compassionate spirit give him an aura of protectiveness, making him a person of strength and courage in difficult moments.\"}\n",
      "    \n",
      "\n",
      "\n",
      "        User: Generate a tuple with first part a key built like this [product ,theme, details], \n",
      "                and the value in the tuple will be a gingle of maximum 100 words with commercial for the given product, in the given theme incorporating the provided details.\n",
      "        AI: {\"key\":[\"Whiskers\",\"happy\",\"cat food-holiday season price reductions-great for your cat\"],\"story\":\"We are so happy to announce holiday discounts for the best cat food outhere! For happy and healthy cat choose Whiskers! Meow!\"}\n",
      "    \n",
      "\n",
      "\n",
      "        User: Generate a tuple with first part a key built like this [fictional character ,location, adventure], \n",
      "                and the value in the tuple will be a story of maximum 100 words describing an adventure of the given fictional character in the provided location.\n",
      "        AI: {\"key\":[\"Baba Yaga\",\"Asia\",\"getting no respect\"],\"story\":\"Once upon a time Baba Yaga wondered far far away from her home and ended up in remote Hokkaido island. \\n                    She was used to locals showing her great respect out of fear and also because she was always one of the pillars of Slavic culture. \\n                    But in Hokkaido the locals knew nothing about her, and she was very disappointed because they have shown her no respect. Eventually she decided there is no place like home and went back\"}\n",
      "    \n",
      "\n",
      "\n",
      "    User: Generate a tuple with first part a key built like this [news agency, location, news item], and the value in the tuple will be an entire news item of maximum 100 words .The news item will be a report of the given news agency regarding the provided location and revolving around the news item which takes place in that location. Be very precise and stick to the facts with the key parameters values.\n",
      "    AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "first string: Reuters, New York City, terrorist attack\n",
      "second string: In a recent report by Reuters, a terrorist attack was reported to have taken place in the bustling metropolis of New York City. \n",
      " According to eyewitnesses, the attack occurred in Times Square, causing chaos and panic among the city's inhabitants. \n",
      " Authorities are currently investigating the incident and trying to mitigate the impact of this heinous act on the residents of New York City. \n",
      " More updates to follow as the story develops.\n"
     ]
    }
   ],
   "source": [
    "df = createDataset(1, 'news agency, location, news item', 'news item','The news item will be a report of the given news agency regarding the provided location and revolving around the news item which takes place in that location','Be very precise and stick to the facts with the key parameters values.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e60dc95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>keywords</th>\n",
       "      <th>story_type</th>\n",
       "      <th>instructions</th>\n",
       "      <th>generated_key</th>\n",
       "      <th>generated_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>news agency, location, news item</td>\n",
       "      <td>news item</td>\n",
       "      <td>The news item will be a report of the given ne...</td>\n",
       "      <td>Reuters, New York City, terrorist attack</td>\n",
       "      <td>In a recent report by Reuters, a terrorist att...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           keywords story_type  \\\n",
       "0  news agency, location, news item  news item   \n",
       "\n",
       "                                        instructions  \\\n",
       "0  The news item will be a report of the given ne...   \n",
       "\n",
       "                              generated_key  \\\n",
       "0  Reuters, New York City, terrorist attack   \n",
       "\n",
       "                                     generated_value  \n",
       "0  In a recent report by Reuters, a terrorist att...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
